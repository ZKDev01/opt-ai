from typing import List

from src.data_manipulation import ExpressionsManipulation, load_prompts
from src.structured_output import StructuredOutput
from src.schema.solver import Solver
from src.schema.math_model import MathModel

from langchain_ollama import ChatOllama
from langchain_core.messages import HumanMessage,AIMessage,BaseMessage



class ChatHistory:
  def __init__(self,temperature:float=0.7) -> None:
    self.llm = ChatOllama(model='llama3.2:latest',temperature=temperature)

  def easy_query (self,query:str) -> BaseMessage:
    return self.llm.invoke(query)

  def process_query (self,query:MathModel,attempts:List=[],k_max:int=5) -> str:
    if not k_max:
      return "No se pudo encontrar una solucion basica factible",attempts
    
    #* generate schema+prompt
    structured_output = StructuredOutput(query)
    prompts = load_prompts()
    solver = Solver(**prompts['meta-basic-solver'])
    schema = structured_output.generate_new_schema(solver,query,attempts)
    
    structured_llm = self.llm.with_structured_output(schema)
    output = structured_llm.invoke(str(query))
    # schema == prompt of user 
    # output + evaluation == answer generated by llm

    exprs,evaluation = structured_output.evaluate_output(output)
    data = ExpressionsManipulation()
    for e in exprs:
      data.add(e)

    #TODO save schema+output in chat 

    print("Intentos restantes: {}\nResultados de Evaluacion: {}".format(k_max-1,evaluation))
    print("Output: {}".format(output))
    attempts.append(output)

    if evaluation:
      return output,attempts
    else:
      return self.process_query (query=query,attempts=attempts,k_max=k_max-1)

